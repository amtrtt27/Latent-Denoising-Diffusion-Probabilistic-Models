11/17/2024 03:48:37 - INFO - __main__ - ***** Training arguments *****
11/17/2024 03:48:37 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='./data/imagenet100_128x128', image_size=128, batch_size=30, num_workers=4, num_classes=100, run_name='exp-11-ddpm', output_dir='experiments', num_epochs=10, learning_rate=0.001, weight_decay=0.0001, grad_clip=1.0, seed=42, mixed_precision='none', num_train_timesteps=1000, num_inference_steps=50, beta_start=0.0001, beta_end=0.02, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, unet_in_size=128, unet_in_ch=3, unet_ch=128, unet_ch_mult=[1, 2, 2, 4], unet_attn=[2, 3], unet_num_res_blocks=2, unet_dropout=0.0, latent_ddpm=False, use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt=None, predictor_type='epsilon', distributed=False, world_size=1, rank=0, local_rank=0, device='cuda', total_batch_size=30, max_train_steps=43340)
11/17/2024 03:48:37 - INFO - __main__ - ***** Running training *****
11/17/2024 03:48:37 - INFO - __main__ -   Num examples = 130000
11/17/2024 03:48:37 - INFO - __main__ -   Num Epochs = 10
11/17/2024 03:48:37 - INFO - __main__ -   Instantaneous batch size per device = 30
11/17/2024 03:48:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 30
11/17/2024 03:48:37 - INFO - __main__ -   Total optimization steps per epoch 4334
11/17/2024 03:48:37 - INFO - __main__ -   Total optimization steps = 43340
/home/ubuntu/idl/Latent-Denoising-Diffusion-Probabilistic-Models/train.py:271: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
  0%|                                                                                                                                                                                 | 0/4334 [00:00<?, ?it/s]11/17/2024 03:48:37 - INFO - __main__ - Epoch 1/10
/home/ubuntu/idl/Latent-Denoising-Diffusion-Probabilistic-Models/train.py:323: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
  0%|                                                                                                                                                                       | 1/4334 [00:01<2:06:01,  1.75s/it]11/17/2024 03:48:39 - INFO - __main__ - Epoch 1/10, Step 0/4334, Loss 0.9979665279388428 (0.9979665279388428)
  2%|███▉                                                                                                                                                                   | 101/4334 [01:19<55:10,  1.28it/s]11/17/2024 03:49:57 - INFO - __main__ - Epoch 1/10, Step 100/4334, Loss 0.03751577436923981 (0.32691375973938713)
  5%|███████▋                                                                                                                                                               | 201/4334 [02:38<53:52,  1.28it/s]11/17/2024 03:51:15 - INFO - __main__ - Epoch 1/10, Step 200/4334, Loss 0.047680504620075226 (0.18417893659175183)
  7%|███████████▌                                                                                                                                                           | 301/4334 [03:56<52:33,  1.28it/s]11/17/2024 03:52:33 - INFO - __main__ - Epoch 1/10, Step 300/4334, Loss 0.013237700797617435 (0.13353332574866045)
  9%|███████████████▍                                                                                                                                                       | 401/4334 [05:14<51:15,  1.28it/s]11/17/2024 03:53:51 - INFO - __main__ - Epoch 1/10, Step 400/4334, Loss 0.028858212754130363 (0.10757649227038509)
 12%|███████████████████▎                                                                                                                                                   | 501/4334 [06:32<49:57,  1.28it/s]11/17/2024 03:55:10 - INFO - __main__ - Epoch 1/10, Step 500/4334, Loss 0.02964601293206215 (0.09155598098408438)
 14%|███████████████████████▏                                                                                                                                               | 601/4334 [07:50<48:39,  1.28it/s]11/17/2024 03:56:28 - INFO - __main__ - Epoch 1/10, Step 600/4334, Loss 0.04685201123356819 (0.0810173373861539)
 16%|███████████████████████████                                                                                                                                            | 701/4334 [09:09<47:20,  1.28it/s]11/17/2024 03:57:46 - INFO - __main__ - Epoch 1/10, Step 700/4334, Loss 0.03336181864142418 (0.07343919632475446)
 18%|██████████████████████████████▊                                                                                                                                        | 801/4334 [10:27<46:02,  1.28it/s]11/17/2024 03:59:04 - INFO - __main__ - Epoch 1/10, Step 800/4334, Loss 0.04284929111599922 (0.0675063245847226)
 21%|██████████████████████████████████▋                                                                                                                                    | 901/4334 [11:45<44:44,  1.28it/s]11/17/2024 04:00:22 - INFO - __main__ - Epoch 1/10, Step 900/4334, Loss 0.040646862238645554 (0.06307934070694426)
 23%|██████████████████████████████████████▎                                                                                                                               | 1001/4334 [13:03<43:26,  1.28it/s]11/17/2024 04:01:41 - INFO - __main__ - Epoch 1/10, Step 1000/4334, Loss 0.014258249662816525 (0.05920646771496454)
 25%|██████████████████████████████████████████▏                                                                                                                           | 1101/4334 [14:21<42:07,  1.28it/s]11/17/2024 04:02:59 - INFO - __main__ - Epoch 1/10, Step 1100/4334, Loss 0.041908394545316696 (0.056027209668333126)
 28%|██████████████████████████████████████████████                                                                                                                        | 1201/4334 [15:40<40:50,  1.28it/s]11/17/2024 04:04:17 - INFO - __main__ - Epoch 1/10, Step 1200/4334, Loss 0.025225305929780006 (0.053289349414609825)
 30%|█████████████████████████████████████████████████▊                                                                                                                    | 1301/4334 [16:58<39:31,  1.28it/s]11/17/2024 04:05:35 - INFO - __main__ - Epoch 1/10, Step 1300/4334, Loss 0.030381163582205772 (0.05101534856918578)
 32%|█████████████████████████████████████████████████████▋                                                                                                                | 1401/4334 [18:16<38:13,  1.28it/s]11/17/2024 04:06:53 - INFO - __main__ - Epoch 1/10, Step 1400/4334, Loss 0.026872407644987106 (0.049068396391850934)
 35%|█████████████████████████████████████████████████████████▍                                                                                                            | 1501/4334 [19:34<36:55,  1.28it/s]11/17/2024 04:08:12 - INFO - __main__ - Epoch 1/10, Step 1500/4334, Loss 0.033561378717422485 (0.04748076030818235)
 37%|█████████████████████████████████████████████████████████████▎                                                                                                        | 1601/4334 [20:52<35:37,  1.28it/s]11/17/2024 04:09:30 - INFO - __main__ - Epoch 1/10, Step 1600/4334, Loss 0.010021003894507885 (0.04592836092311719)
 39%|█████████████████████████████████████████████████████████████████▏                                                                                                    | 1701/4334 [22:11<34:18,  1.28it/s]11/17/2024 04:10:48 - INFO - __main__ - Epoch 1/10, Step 1700/4334, Loss 0.021480346098542213 (0.04460983316133183)
 42%|████████████████████████████████████████████████████████████████████▉                                                                                                 | 1801/4334 [23:29<33:00,  1.28it/s]11/17/2024 04:12:06 - INFO - __main__ - Epoch 1/10, Step 1800/4334, Loss 0.02139221876859665 (0.043376259594950936)
 44%|████████████████████████████████████████████████████████████████████████▊                                                                                             | 1901/4334 [24:47<31:42,  1.28it/s]11/17/2024 04:13:24 - INFO - __main__ - Epoch 1/10, Step 1900/4334, Loss 0.023588355630636215 (0.04229520569687248)
 46%|████████████████████████████████████████████████████████████████████████████▋                                                                                         | 2001/4334 [26:05<30:24,  1.28it/s]11/17/2024 04:14:43 - INFO - __main__ - Epoch 1/10, Step 2000/4334, Loss 0.03505454212427139 (0.0413615293835738)
 48%|████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 2101/4334 [27:23<29:06,  1.28it/s]11/17/2024 04:16:01 - INFO - __main__ - Epoch 1/10, Step 2100/4334, Loss 0.03168570622801781 (0.04048526820539187)
 51%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 2201/4334 [28:42<27:47,  1.28it/s]11/17/2024 04:17:19 - INFO - __main__ - Epoch 1/10, Step 2200/4334, Loss 0.02692476473748684 (0.03963267837000714)
 53%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                             | 2301/4334 [30:00<26:29,  1.28it/s]11/17/2024 04:18:37 - INFO - __main__ - Epoch 1/10, Step 2300/4334, Loss 0.0267763864248991 (0.038845717639818964)
 55%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 2401/4334 [31:18<25:11,  1.28it/s]11/17/2024 04:19:55 - INFO - __main__ - Epoch 1/10, Step 2400/4334, Loss 0.01805143617093563 (0.03818552424240607)
 58%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 2501/4334 [32:36<23:53,  1.28it/s]11/17/2024 04:21:14 - INFO - __main__ - Epoch 1/10, Step 2500/4334, Loss 0.028403256088495255 (0.037583395200478036)
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 2601/4334 [33:54<22:35,  1.28it/s]11/17/2024 04:22:32 - INFO - __main__ - Epoch 1/10, Step 2600/4334, Loss 0.011585482396185398 (0.03697988647152625)
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 2701/4334 [35:13<21:17,  1.28it/s]11/17/2024 04:23:50 - INFO - __main__ - Epoch 1/10, Step 2700/4334, Loss 0.01824117824435234 (0.0364120379188579)
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 2801/4334 [36:31<19:58,  1.28it/s]11/17/2024 04:25:08 - INFO - __main__ - Epoch 1/10, Step 2800/4334, Loss 0.027871349826455116 (0.035895532700813367)
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 2901/4334 [37:49<18:40,  1.28it/s]11/17/2024 04:26:26 - INFO - __main__ - Epoch 1/10, Step 2900/4334, Loss 0.010876373387873173 (0.0354268663148378)
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 3001/4334 [39:07<17:22,  1.28it/s]11/17/2024 04:27:45 - INFO - __main__ - Epoch 1/10, Step 3000/4334, Loss 0.007623272482305765 (0.03498447397183807)
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 3101/4334 [40:25<16:04,  1.28it/s]11/17/2024 04:29:03 - INFO - __main__ - Epoch 1/10, Step 3100/4334, Loss 0.0128938602283597 (0.03455159978737459)
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 3201/4334 [41:44<14:45,  1.28it/s]11/17/2024 04:30:21 - INFO - __main__ - Epoch 1/10, Step 3200/4334, Loss 0.033570755273103714 (0.03410950591646587)
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 3301/4334 [43:02<13:27,  1.28it/s]11/17/2024 04:31:39 - INFO - __main__ - Epoch 1/10, Step 3300/4334, Loss 0.04465245082974434 (0.03370508909039538)
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 3401/4334 [44:20<12:09,  1.28it/s]11/17/2024 04:32:57 - INFO - __main__ - Epoch 1/10, Step 3400/4334, Loss 0.02784915082156658 (0.033376377528222256)
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 3501/4334 [45:38<10:51,  1.28it/s]11/17/2024 04:34:16 - INFO - __main__ - Epoch 1/10, Step 3500/4334, Loss 0.018086789175868034 (0.03305538540544567)
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 3601/4334 [46:56<09:33,  1.28it/s]11/17/2024 04:35:34 - INFO - __main__ - Epoch 1/10, Step 3600/4334, Loss 0.01559887919574976 (0.032709485959917024)
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 3701/4334 [48:15<08:14,  1.28it/s]11/17/2024 04:36:52 - INFO - __main__ - Epoch 1/10, Step 3700/4334, Loss 0.02678903564810753 (0.0324128929112797)
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 3801/4334 [49:33<06:56,  1.28it/s]11/17/2024 04:38:10 - INFO - __main__ - Epoch 1/10, Step 3800/4334, Loss 0.022222723811864853 (0.032129952283620235)
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 3901/4334 [50:51<05:38,  1.28it/s]11/17/2024 04:39:28 - INFO - __main__ - Epoch 1/10, Step 3900/4334, Loss 0.02039235830307007 (0.03184149597420041)
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 4001/4334 [52:09<04:20,  1.28it/s]11/17/2024 04:40:47 - INFO - __main__ - Epoch 1/10, Step 4000/4334, Loss 0.02189186029136181 (0.03160069438419823)
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4101/4334 [53:27<03:02,  1.28it/s]11/17/2024 04:42:05 - INFO - __main__ - Epoch 1/10, Step 4100/4334, Loss 0.02907979115843773 (0.03134915392029003)
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 4201/4334 [54:46<01:44,  1.28it/s]11/17/2024 04:43:23 - INFO - __main__ - Epoch 1/10, Step 4200/4334, Loss 0.026671551167964935 (0.031100032305463765)
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 4301/4334 [56:04<00:25,  1.28it/s]11/17/2024 04:44:41 - INFO - __main__ - Epoch 1/10, Step 4300/4334, Loss 0.017759107053279877 (0.030900337437648043)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4334/4334 [56:29<00:00,  1.28it/s]
Traceback (most recent call last):
  File "/home/ubuntu/idl/Latent-Denoising-Diffusion-Probabilistic-Models/train.py", line 407, in <module>
    main()
  File "/home/ubuntu/idl/Latent-Denoising-Diffusion-Probabilistic-Models/train.py", line 381, in main
    guidance_scale=args.guidance_scale,
                   ^^^^^^^^^^^^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'guidance_scale'. Did you mean: 'cfg_guidance_scale'?
